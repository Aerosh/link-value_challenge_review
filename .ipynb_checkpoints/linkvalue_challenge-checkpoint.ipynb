{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Challenge\n",
    "\n",
    "## Définition du problème \n",
    "\n",
    "Dans ce challenge, nous allons explorer divers méthodes afin de prédire si la review d'un utilisateur peut être utile pour les autres utilisateurs.\n",
    "\n",
    "Ici, il s'agit d'une prédiction binaire uniquement, \"utile\" ou \"inutile\", et nous disposons de reviews de PriceMinister. \n",
    "\n",
    "Dans un premier temps, nous allons explorer le dataset fourni pour déterminer les éléments clés nécessaire afin d'obtenir un modèle adéquat à notre problèmatique. Nous allons notamment sélectionner et construire les différentes features dont nous aurions besoin.\n",
    "\n",
    "Ensuite, nous allons passer à la partie de classification, avec une sélection et comparaison de plusieurs modèles et méthodes, afin d'avoir une vue d'ensemble sur les choix à effectuer.\n",
    "\n",
    "Enfin, nous finirons sur une discussion des différents résultats et une mise en place des différents éléments pour la submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "\n",
    "# Mathematic libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP tools\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, RandomTreesEmbedding,\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Utils\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import re\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pre-built function\n",
    "def train_eval_class(classifier, train_x, train_y, val_x, val_y_true):\n",
    "    # training classifier with training data\n",
    "    clf = classifier.fit(train_x, train_y)\n",
    "\n",
    "    # Prediction on validation set\n",
    "    val_y_hat = clf.predict(val_x)\n",
    "\n",
    "    # Validation set score\n",
    "    return roc_auc_score(val_y_true, val_y_hat)\n",
    "\n",
    "\n",
    "def score_function(y_true, y_pred):\n",
    "    # Classifier score\n",
    "    return roc_auc_score( y_true , y_pred )\n",
    "\n",
    "    \n",
    "\n",
    "# Custom tranform class for NaiveBaysan classification\n",
    "class SparseMatrixToDenseArray(object):\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.toarray()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.\n",
    "    Extract column from panda DataFrame\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key : hashable, required\n",
    "        The key corresponding to the desired value in a mappable.\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]\n",
    "    \n",
    "class TextStats(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" For text type data, retrieve number of characters, words and sentences, usually\n",
    "        used in radibilty mesures.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, texts):\n",
    "        \"\"\"\n",
    "        Return number of words, characters and sentences, but also text length.\n",
    "        Return in form of list of dict.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"characters\" : len(text) - text.count(' '),\n",
    "                \"words\": len(re.findall(r\"[\\w']+\", text)),\n",
    "                \"sentences\": text.count('.') + text.count('!') + text.count('?'),\n",
    "                \"length\" : len(text)\n",
    "            }\n",
    "            for text in texts\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Input datas\n",
    "\n",
    "# Original datasets\n",
    "train_full = pd.read_csv('data/train.csv', delimiter=';', encoding=\"utf-8\")\n",
    "test = pd.read_csv('data/test.csv', delimiter=';')\n",
    "\n",
    "# Split training into validation/train with ration of 25/75\n",
    "train, val = train_test_split(train_full, test_size = 0.25)\n",
    "\n",
    "# Get true label for trainand valid \n",
    "train_y = train[\"Target\"]\n",
    "val_y_true = val[\"Target\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Tout d'abord, nous allons explorer notre dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review_content</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>product</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>En appelant un acheteur pour demander si l'écr...</td>\n",
       "      <td>La Police s'inscrit en acheteur privé sur Pric...</td>\n",
       "      <td>5</td>\n",
       "      <td>2fbb619e3606f9b7c213e858a109cda771aa2c47ce50d5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alors, là, on a affaire au plus grand Navet ja...</td>\n",
       "      <td>Chef D'Oeuvre Absolu en vue...</td>\n",
       "      <td>5</td>\n",
       "      <td>7b56d9d378d9e999d293f301ac43d044cd7b4786d09afb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Effet garanti sur la terrase. Ils donnent immé...</td>\n",
       "      <td>Effet garanti sur la terrase. Ils donnent immé...</td>\n",
       "      <td>3</td>\n",
       "      <td>7b37bf5dcb2fafd9229897910318a7dfa11a04ca36893c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tres bon rapport qualite prix tre pratique en ...</td>\n",
       "      <td>bon produit</td>\n",
       "      <td>4</td>\n",
       "      <td>77d2dbd504b933ab3aaf7cb0cd81c22f7c3549012f4f88...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Ordinateur de bureau trés bien pour quelqu'un ...</td>\n",
       "      <td>Apple Power MAC G4</td>\n",
       "      <td>3</td>\n",
       "      <td>f574512e7d2dd1dd73c7f8f804bf16f14c932c5651a01b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                     review_content  \\\n",
       "0   0  En appelant un acheteur pour demander si l'écr...   \n",
       "1   1  Alors, là, on a affaire au plus grand Navet ja...   \n",
       "2   2  Effet garanti sur la terrase. Ils donnent immé...   \n",
       "3   3  tres bon rapport qualite prix tre pratique en ...   \n",
       "4   4  Ordinateur de bureau trés bien pour quelqu'un ...   \n",
       "\n",
       "                                        review_title  review_stars  \\\n",
       "0  La Police s'inscrit en acheteur privé sur Pric...             5   \n",
       "1                     Chef D'Oeuvre Absolu en vue...             5   \n",
       "2  Effet garanti sur la terrase. Ils donnent immé...             3   \n",
       "3                                        bon produit             4   \n",
       "4                                 Apple Power MAC G4             3   \n",
       "\n",
       "                                             product  Target  \n",
       "0  2fbb619e3606f9b7c213e858a109cda771aa2c47ce50d5...       0  \n",
       "1  7b56d9d378d9e999d293f301ac43d044cd7b4786d09afb...       1  \n",
       "2  7b37bf5dcb2fafd9229897910318a7dfa11a04ca36893c...       0  \n",
       "3  77d2dbd504b933ab3aaf7cb0cd81c22f7c3549012f4f88...       1  \n",
       "4  f574512e7d2dd1dd73c7f8f804bf16f14c932c5651a01b...       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10fffbd10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEJCAYAAACDscAcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npCL/D457qUKxaccCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103a49e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Proportion of useful and not useful reviews\n",
    "sns.countplot(x=\"Target\", data=train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10db69b10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEHCAYAAAC5u6FsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGO9JREFUeJzt3X+wX3V95/HnJYEE9CabnblIf7i6sO1rU7cojSUoRNMa\ni9BV1HW3LaOlMvJLuugsU11MUNnFYUShS3CFXVCBgh0UhHZigWxXgSTdBqUwwjb7Fti6OnadvWtD\ncm0WYuDuH+dEvobcHyfJ936Te5+Pme/M9/s5n3Pu+3z/+L7u53zOj6Hx8XEkSZquwwZdgCTp0GJw\nSJI6MTgkSZ0YHJKkTgwOSVInBockqZP5/dx4kqOBh4E3A7uAm4Bx4HHgwqp6Psk5wHnt8sural2S\nI4FbgaOBMeCsqhpNchJwTdt3fVVd1s/6JUkvNtSv6ziSHA58CXgV8DbgSuDqqro/yfXAfcB/A/4L\n8FpgIbCxfX8hsKiqPp7kt4HXVdUHkjwK/AvgfwJfBVZX1SOT1TE6OuaFKpLU0cjI8NBEy/p5qOrT\nwPXA37aflwEPtO/vAVYBJwKbqurZqtoGPAkcD5wC3NvbN8kiYEFVPVVV4zTBs6qP9UuS9qIvh6qS\n/B4wWlX3JbmkbR5qf/ChOfy0GFgEbOtZdW/tvW3b9+h77FS1LFlyFPPnz9vHPZEk7alfcxxnA+NJ\nVgGvAW6hma/YbRh4miYIhqdon6rvpLZu3bFveyBJc9jIyPCEy/pyqKqq3lBVb6yqlcCjwO8C9yRZ\n2XY5DdgAPASsSLIwyWJgKc3E+Sbg9N6+VbUd2JnkuCRDwKntNiRJM6ivZ1Xt4WLghiRHAFuAO6rq\nuSRraQLgMJrJ7meSXAfcnGQjsBM4s93G+cBtwDyas6o2z2D9kiT6eFbVwcKzqiSpu0GdVSVJmoUM\nDklSJwaHJKkTg0OS1MlMnlUlSYesLZuvGnQJB9zS5Rfv03qOOCRJnRgckqRODA5JUicGhySpE4ND\nktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6qRvt1VPMg+4AQgw\nDpwPHA6sA55ou11XVbcnOQc4D9gFXF5V65IcCdwKHA2MAWdV1WiSk4Br2r7rq+qyfu2DJOnF+jni\neCtAVZ0MrAE+ASwDrq6qle3r9iTHABcBJwOnAlckWQBcADxWVSuAW9ptAFwPnAmcAixPckIf90GS\ntIe+BUdV3Q2c2358BfA0TXD8ZpIHk3wuyTBwIrCpqp6tqm3Ak8DxNMFwb7v+PcCqJIuABVX1VFWN\nA/cBq/q1D5KkF+vrEwCraleSm4F3AO8Cfg64saoeTrIa+BjwKLCtZ7UxYDGwqKe9t237Hn2PnayG\nJUuOYv78eQdgbyTNZVsGXUAfjIwM79N6fX90bFWdleTDwGbg9VX1/XbRXcC1wINAb/XDNKOT7T3t\ne2vrbZ/Q1q079ncXJGlWGh0dm3DZZKHSt0NVSd6T5JL24w7geeArSU5s294EPAw8BKxIsjDJYmAp\n8DiwCTi97XsasKGqtgM7kxyXZIhmTmRDv/ZBkvRi/RxxfAX4QpIHac6m+iDwPeDaJD8GfgCcW1Xb\nk6ylCYDDgNVV9UyS64Cbk2wEdtJMiENzdtZtwDyas6o293EfJEl7GBofHx90DX01Ojo2u3dQ0ozY\nsvmqQZdwwC1dfvGEy0ZGhocmWuYFgJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgk\nSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqZP5\n/dpwknnADUCAceB84Bngpvbz48CFVfV8knOA84BdwOVVtS7JkcCtwNHAGHBWVY0mOQm4pu27vqou\n69c+SJJerJ8jjrcCVNXJwBrgE8DVwJqqWgEMAWckOQa4CDgZOBW4IskC4ALgsbbvLe02AK4HzgRO\nAZYnOaGP+yBJ2kPfgqOq7gbObT++AngaWAY80LbdA6wCTgQ2VdWzVbUNeBI4niYY7u3tm2QRsKCq\nnqqqceC+dhuSpBnSt0NVAFW1K8nNwDuAdwFvbn/woTn8tBhYBGzrWW1v7b1t2/foe+xkNSxZchTz\n58/bzz2RNNdtGXQBfTAyMrxP6/U1OACq6qwkHwY2A0f2LBqmGYVsb99P1j5V3wlt3bpjf8qXpFlr\ndHRswmWThUrfDlUleU+SS9qPO4DngW8mWdm2nQZsAB4CViRZmGQxsJRm4nwTcHpv36raDuxMclyS\nIZo5kQ392gdJ0ov1c8TxFeALSR4EDgc+SDPauyHJEe37O6rquSRraQLgMGB1VT2T5Drg5iQbgZ00\nE+LQnJ11GzCP5qyqzX3cB0nSHobGx8en7nUIGx0dm907KGlGbNl81aBLOOCWLr94wmUjI8NDEy3z\nAkBJUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktSJwSFJ\n6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktTJ/H5sNMnhwOeBVwILgMuB7wHrgCfa\nbtdV1e1JzgHOA3YBl1fVuiRHArcCRwNjwFlVNZrkJOCatu/6qrqsH/VLkibWrxHHu4EfVtUK4C3A\nZ4BlwNVVtbJ93Z7kGOAi4GTgVOCKJAuAC4DH2vVvAda0270eOBM4BVie5IQ+1S9JmkBfRhzAl4E7\n2vdDNCOEZUCSnEEz6vggcCKwqaqeBZ5N8iRwPE0wXNmufw9waZJFwIKqeopmQ/cBq4BH+rQPkqS9\n6EtwVNWPAJIM0wTIGppDVjdW1cNJVgMfAx4FtvWsOgYsBhb1tPe2bd+j77FT1bJkyVHMnz9vv/ZH\nkrYMuoA+GBkZ3qf1+jXiIMnLgbuAz1bVF5P8g6p6ul18F3At8CDQW/kw8DRNQAxP0tbbPqmtW3fs\nz25I0qw1Ojo24bLJQqUvcxxJXgasBz5cVZ9vm+9LcmL7/k3Aw8BDwIokC5MsBpYCjwObgNPbvqcB\nG6pqO7AzyXFJhmjmRDb0o35J0sT6NeL4CLCEZm7i0rbt3wB/mOTHwA+Ac6tqe5K1NAFwGLC6qp5J\nch1wc5KNwE6aCXGA84HbgHk0Z1Vt7lP9kqQJDI2Pjw+6hr4aHR2b3TsoaUZs2XzVoEs44JYuv3jC\nZSMjw0MTLfMCQElSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKmT\naQVHkmv30nbzgS9HknSwm/Qmh0lupHnmxWuTvKpn0eE0z8iQJM0xU90d93Ka54ZfA/Q+33sXs/O5\nJpKkKUwaHFX1HeA7wKvbR7cupnkULMBLgb/rZ3GSpIPPtJ7HkeQS4BLghz3N40zj0a2SpNllug9y\neh9wXFWN9rMYSdLBb7qn434XD0tJkpj+iOMJYGOSrwPP7G6sqn/Xl6okSQet6QbH99sXvDA5Lkma\ng6YVHFV12dS9XpDkcODzNKfyLqA5rfevgZtoJtUfBy6squeTnAOcR3OK7+VVtS7JkcCtwNHAGHBW\nVY0mOYnm1OBdwPqudUmS9t90rxx/Pslze7y+N8kq7wZ+WFUrgLcAnwGuBta0bUPAGUmOAS4CTgZO\nBa5IsgC4AHis7XsLsKbd7vXAmcApwPIkJ3TdYUnS/pnuiOMnAdOOJt4OvG6SVb4M3NG+H6IZISwD\nHmjb7gF+A3gO2FRVzwLPJnkSOJ4mGK7s6Xtpex3Jgqp6qq3jPmAV8Mh09kGSdGBMd47jJ6rqx8CX\nk6yepM+PAJIM0wTIGuDTVTXedhmjuZhwEbCtZ9W9tfe2bd+j75TXkSxZchTz58+besckaRKz8VYZ\nIyPD+7TedC8A/N2ej0PAq4CdU6zzcuAu4LNV9cUkV/YsHgaepgmC4Snap+o7qa1bd0zVRZLmpNHR\nsQmXTRYq072O49d6Xm9s235ros5JXgasBz5cVZ9vmx9JsrJ9fxqwAXgIWJFkYZLFwFKaifNNwOm9\nfatqO7AzyXFJhmjmRDZMs35J0gEy3TmO97ZzG2nXebyqdk2yykeAJTRzE5e2bR8A1iY5gmbUd0dV\nPZdkLU0AHAasrqpnklwH3JxkI83I5sx2G+cDtwHzaM6q2txlZyVJ+29ofHx8yk5JlgF30tyr6jDg\nZcA7DoUf7tHRsal3UJKmsGXzVYMu4YBbuvziCZeNjAxPeM3edCfH1wK/tTso2usprgVO7FCjJGkW\nmO4cx0t7RxdV9ZfAwv6UJEk6mE03OP4uyRm7PyR5Oz99i3VJ0hwx3UNV5wLrknyO5nTcceD1fatK\nknTQmu6I4zRgB/AKmlNyR4GVfapJknQQm25wnAucXFV/X1Xforl9yL/uX1mSpIPVdIPjcH76SvGd\nNIerJElzzHTnOO4GvpbkS+3ndwJ/0p+SJEkHs2mNOKrqwzTXcoTmxoJrq+rSydeSJM1G0747blXd\nwQu3SpckzVHTneOQJAkwOCRJHRkckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjqZ9pXj\n+yLJcuCTVbUyyQnAOuCJdvF1VXV7knOA84BdwOVVtS7JkcCtwNHAGHBWVY22j6y9pu27vqou62f9\nkqQX69uII8mHgBt54RGzy4Crq2pl+7o9yTHARcDJwKnAFUkWABcAj1XVCuAWYE27jeuBM4FTgOVt\nGEmSZlA/D1U9RXMX3d2WAb+Z5MEkn0syDJwIbKqqZ6tqG/AkcDxNMNzbrncPsCrJImBBVT1VVePA\nfcCqPtYvSdqLvh2qqqo7k7yyp+kh4MaqejjJauBjwKPAtp4+Y8BiYFFPe2/b9j36HjtVHUuWHMX8\n+fP2dTckCYAtgy6gD0ZGhvdpvb7Ocezhrqp6evd74FrgQaC38mHgaZqAGJ6krbd9Ulu37ti/qiVp\nlhodHZtw2WShMpNnVd2X5MT2/ZuAh2lGISuSLEyyGFgKPA5sAk5v+54GbKiq7cDOJMclGaKZE9kw\ng/VLkpjZEccFwLVJfgz8ADi3qrYnWUsTAIcBq6vqmSTXATcn2UjzmNoz222cD9wGzKM5q2rzDNYv\nSQKGxsdn96PDR0fHZvcOSpoRWzZfNegSDrilyy+ecNnIyPDQRMu8AFCS1InBIUnqxOCQJHVicEiS\nOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJzP5\nICdJh5gb/sO9gy7hgDvng28ZdAmHPEcckqRODA5JUicGhySpk77OcSRZDnyyqlYm+SfATcA48Dhw\nYVU9n+Qc4DxgF3B5Va1LciRwK3A0MAacVVWjSU4Crmn7rq+qy/pZvyTpxfo24kjyIeBGYGHbdDWw\npqpWAEPAGUmOAS4CTgZOBa5IsgC4AHis7XsLsKbdxvXAmcApwPIkJ/SrfknS3vXzUNVTwDt7Pi8D\nHmjf3wOsAk4ENlXVs1W1DXgSOJ4mGO7t7ZtkEbCgqp6qqnHgvnYbkqQZ1LdDVVV1Z5JX9jQNtT/4\n0Bx+WgwsArb19Nlbe2/b9j36HjtVHUuWHMX8+fP2ZRckzUIjI8P7tN6WA1zHwWBfv4uZvI7j+Z73\nw8DTNEEwPEX7VH0ntXXrjn2vWNKsMzo6NugSDhqTfReThcpMnlX1SJKV7fvTgA3AQ8CKJAuTLAaW\n0kycbwJO7+1bVduBnUmOSzJEMyeyYQbrlyQxsyOOi4EbkhxBM+q7o6qeS7KWJgAOA1ZX1TNJrgNu\nTrIR2EkzIQ5wPnAbMI/mrKrNM1i/JAkYGh8fn7rXIWx0dGx276DUR95y5AVbNl91gCsZvKXLL55w\n2cjI8NBEy7wAUJLUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE\n4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdTJ/pv9gkr8Ctrcf/wb4\nBHATMA48DlxYVc8nOQc4D9gFXF5V65IcCdwKHA2MAWdV1egM74IkzWkzOuJIshAYqqqV7eu9wNXA\nmqpaAQwBZyQ5BrgIOBk4FbgiyQLgAuCxtu8twJqZrF+SNPMjjlcDRyVZ3/7tjwDLgAfa5fcAvwE8\nB2yqqmeBZ5M8CRwPnAJc2dP30hmsXZLEzAfHDuDTwI3AL9D8+A9V1Xi7fAxYDCwCtvWst7f23W2T\nWrLkKObPn3dAipd06BsZGd6n9bYc4DoOBvv6Xcx0cHwbeLINim8n+SHNiGO3YeBpmjmQ4Snad7dN\nauvWHQegbEmzxejo2KBLOGhM9l1MFiozHRxnA78MvD/Jz9KMINYnWVlV9wOnAV8HHgI+0c6JLACW\n0kycbwJOb5efBmyY4fo1B3zj4osGXUJf/OpVawddgmaJmQ6OzwE3JdlIcxbV2cD/BW5IcgTNaPCO\nqnouyVqaYDgMWF1VzyS5Dri5XX8ncOYM1y9Jc96MBkdVTfRj/8a99L0BuGGPth3Av+xPdZKk6fAC\nQElSJzN+AeDB5AOf+tNBl9AX1/zB2wZdgqRZzBGHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmd\nGBySpE4MDklSJwaHJKkTg0OS1MmcvuWIXvAH62bnU3g/9c8vH3QJ0qzjiEOS1InBIUnqxOCQJHVi\ncEiSOjE4JEmdGBySpE4OudNxkxwGfBZ4NfAs8L6qenKwVUnS3HEojjjeDiysqtcB/xa4asD1SNKc\ncigGxynAvQBV9ZfAawdbjiTNLUPj4+ODrqGTJDcCd1bVPe3n7wLHVtWuwVYmSXPDoTji2A4M93w+\nzNCQpJlzKAbHJuB0gCQnAY8NthxJmlsOubOqgLuANyf5C2AIeO+A65GkOeWQm+OQJA3WoXioSpI0\nQAaHJKmTQ3GO45CTZDnwyapaOehaBiXJ4cDngVcCC4DLq+pPB1rUgCSZB9wABBgHzq+qxwdb1WAl\nORp4GHhzVf2PQdczKEn+iubMUYC/qaqDcg7X4OizJB8C3gP8/aBrGbB3Az+sqvck+YfAo8CcDA7g\nrQBVdXKSlcAngDMGWtEAtf9U/Cfg/w26lkFKshAYOhT+wfRQVf89Bbxz0EUcBL4MXNq+HwLm7LU3\nVXU3cG778RXA0wMs52DwaeB64G8HXciAvRo4Ksn6JF9rLzc4KBkcfVZVdwI/HnQdg1ZVP6qqsSTD\nwB3A7HzI+TRV1a4kNwPXArcNup5BSfJ7wGhV3TfoWg4CO2hC9FTgfOC2JAflUSGDQzMmycuBrwN/\nVFVfHHQ9g1ZVZwG/CNyQ5CWDrmdAzqa5Lut+4DXALUmOGWxJA/Nt4NaqGq+qbwM/BH5mwDXt1UGZ\nZpp9krwMWA/8flX910HXM0hJ3gP8fFVdQfNf5vPta86pqjfsft+Gx/lV9YPBVTRQZwO/DLw/yc8C\ni4D/PdiS9s7g0Ez5CLAEuDTJ7rmO06pqLk6IfgX4QpIHgcOBD87R70E/7XPATUk20pxtd/bBeh8+\nrxyXJHXiHIckqRODQ5LUicEhSerE4JAkdWJwSJI6MTik/ZTkz9rz7mfq752b5Hdm6u9Je/I6Dmk/\nVdXpM/wnXw/cP8N/U/oJr+OQgPYutVcC84DvAD8C/ln7+ZNV9cftLa/PrapvtrdG/1/ArwAPASuB\n7wGfat/PA26qqj9M8hjwr6pqS5LbgO1VdUF7E7uPThQ8SRYBfwzsvgXHZTRXmn+pre8c4Ps097t6\nKXA0cFVVrU3yceAk4B8BnwEWAmfRXKH+UFWdt7/fmeYuD1VJL/hF4NeBJ4CHq2oZ8AZgdZJjgT8C\nfrvt++vAt6rq//Ssfw5AVf0KcCJwRpIVwFeBN7V9jgdOad+fBqybpJ53AN9p63g3sKKq/pzmdvQf\nbW8M+D6aZ5v8KvBrNLdo321hVf0S8J+BS4DXAsuA55P83PS/FumnGRzSC6qqtgGrgPOTPAo8CLwE\neBXNf//vTDIE/A5w6x7rrwLe1q63Gfh5mnsPfRV4U5JfAv478Fz74KKpguMvgLcnuZsmbP79Xvpc\nDCxMcglNaLy0Z9nmdqd2tdv6BvAx4D9W1fen8X1Ie2VwSC/Yfb+oecC7q+o1VfUamkM+97Y33/s2\nzaGoVcDde6w/D/jQHut9geZH+zXtOvcDDwDvAo6oqu9OVExVPQH8U5rbrq8AHmpDq9eXaEYmf01z\nP7C97Q/A24ELaJ6Fcm+SN078NUiTMzikF/sazY8sSX4G+BbNXAE0h6uuAu6vqh17We+cJIcneSmw\nEVheVc/R/Pd/EU1wfA1YDfzZZEUk+X3gsqr6MvB+mjmMxTQPwdp9YsubaQ5b/Qnwxna9eXtsZwTY\nAjxWVR+luUvx8dP9MqQ9GRzSi10GHJnkcZof+Q9V1VPtsruAX+DFh6mgeYrdE8AjwDeBL1TV/e2y\nrwIvaZ+n/QDwMiY/TAVwC5B2cv1B4ONV9TTw58BHkrwL+DiwsZ24P5VmYv8f926kqkZpHs36jSQP\n09yl+KYpvwVpAp5VJUnqxOs4pAFKchxw5wSL31dV35zJeqTpcMQhSerEOQ5JUicGhySpE4NDktSJ\nwSFJ6sTgkCR1YnBIkjr5/5UYMYwYs1IcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1100254d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# review stars distribution\n",
    "sns.countplot(x=\"review_stars\", data = train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 60000\n",
       "unique                                                46293\n",
       "top       5568d0e86c5cc400ce85779617c698e017558dc803e75d...\n",
       "freq                                                    135\n",
       "Name: product, dtype: object"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_full['product'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAEFCAYAAAAymlabAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x148a2a910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Number of product distribution\n",
    "# Replace product by int\n",
    "prod_int = pd.factorize(train_full['product'])[0]\n",
    "train_full['prod_int'] = prod_int\n",
    "# Frequency distrinution\n",
    "prod_freq = pd.Series(prod_int).value_counts()\n",
    "ax = sns.stripplot(x=prod_freq)\n",
    "ax.set(xlabel='nb reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les premières observations sont les suivantes :\n",
    "- Les reviews utiles et inutiles semblent plus ou moins équilibré, de ce fait, un estimateur random ou totalement déterminitique atteignerait déjà les 50% de précision.\n",
    "- La plupart des review ont la note maximal, ce qui en fait un indiquateur peu fiable compte tenu de la proportion de review utiles et inutiles.\n",
    "- La majeure partie de produit n'ont qu'une seule review, mais certains en possède énormémant comparé aux autres. Il pourrait être intéressant de les clusturiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x11009a1d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAADQCAYAAAAalMCAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nApaIiIiIiEiT/P/G6z+yl32H9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f2da6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add feature review length\n",
    "review_length = train_full[\"review_content\"].apply(lambda x : len(x))\n",
    "train_full[\"review_length\"] = review_length\n",
    "facet = sns.FacetGrid( train_full , hue=\"Target\" , aspect=4 )\n",
    "facet.map( sns.kdeplot , \"review_length\" , shade= True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'intuition derrière la longeur de la review, serait de dire que les review inutiles ont tendences à être courtes comparé aux utiles. Malheureusement, notre intuition semble incorrecte aux vues de la distribution ci-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x168d5cfd0>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAD3CAYAAADVEMneAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x168dbe050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Variable correlation matrix\n",
    "corr = train_full.corr()\n",
    "sns.heatmap(corr, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les données, excepté le texte, ne semble pas avoir une influence notable sur l'utilité d'une review. Cependant, des testes plus poussés avec des features NLP pourraient être intéressant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données texte et construction des features NLP\n",
    "Comme nous l'avons observé, les divers features autres que le texte semble peu propice à une bonne classification. \n",
    "Sachant qu'une review est principalement jugé sur son contenu, nous allons construire des features à partir de ce texte en utilisant des technique de NLP. \n",
    "Nous  prenons en compte ici seulement le contenu de la review (\"review_content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordCount \n",
    "Wordcount est l'une des techniques les plus basique qui consiste à construire un vocabulaire à partir des différent textes et à compter les occurences des différents mots pour un seul texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 58727)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count word occurences in text features\n",
    "count_vect = CountVectorizer()\n",
    "train_counts = count_vect.fit_transform(train[\"review_content\"])\n",
    "train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>#occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rilke</td>\n",
       "      <td>46258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cordiament</td>\n",
       "      <td>13380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>woode</td>\n",
       "      <td>56931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bouddhisme</td>\n",
       "      <td>8097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>climatique</td>\n",
       "      <td>11329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>huileux</td>\n",
       "      <td>26802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ausitot</td>\n",
       "      <td>6008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>instalées</td>\n",
       "      <td>28473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>accueille</td>\n",
       "      <td>2442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spiders</td>\n",
       "      <td>50422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  #occurences\n",
       "0       rilke        46258\n",
       "1  cordiament        13380\n",
       "2       woode        56931\n",
       "3  bouddhisme         8097\n",
       "4  climatique        11329\n",
       "5     huileux        26802\n",
       "6     ausitot         6008\n",
       "7   instalées        28473\n",
       "8   accueille         2442\n",
       "9     spiders        50422"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(count_vect.vocabulary_.items()[:10], columns=[\"word\", '#occurences'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons désormais nos différents textes représentés en tant que feature vector dans un vocabulaire composé de l'ensemble des mots. \n",
    "\n",
    "### TF-IDF\n",
    "Wordcount nous a permis d'avoir le nombre d'occurance des mots au sein d'un texte. Cependant, la longueur du texte aura une grande influence sur le nombre de mots qui apparaissent ou même les répétitions. \n",
    "\n",
    "Un autre problème est celui du vocabulaire commun à tous les textes, aussi bien utile que inutile. En effet, il semblerait logique de mettre en avant les termes plutôt \"uniques\" des bonnes reviews que ceux communs à tous. \n",
    "\n",
    "Pour cela, nous utilisons la technique TF-IDF pour \"Term Frequency and Inverse Document Frequency\" qui permet non seulement de prendre en compte l'occurence de certains terme en fonction de la longeur du texte pour en retiré la fréquence de ce term dans le document, mais aussi de pénaliser les termes communs à plusieurs textes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 58727)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce occurences to term frequency and inverse document frequency\n",
    "tfidf_tr = TfidfTransformer()\n",
    "train_tfidf = tfidf_tr.fit_transform(train_counts)\n",
    "train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Sementic Analysis\n",
    "\n",
    "LSA est une méthode de réduction de feature qui permet de relier les différents termes et documents à des \"conceptes\", assez similair aux variables latentes dans les techniques de recommendation basé sur la factorisation de matrice. \n",
    "\n",
    "LSA applique une Singular Value Decomposition (SVD) à la matrice TF-IDF. Cela à plusieurs avantages, notamment celui de réduire le nombre de dimensions à un subset qui est beaucoup plus \"descriptif\". Nous avons donc un matrix features plus dense. \n",
    "\n",
    "Certaines documentations affirment que la SVD réduirait le bruit de notre matrices et la densité apporterait une amélioration de la classification.  Un avantage personnel que nous constatons, c'est la transformation de donnée dite \"dures\" (féquence de mots, ...) à des données plus \"abstraites (conceptes, sujets, ...) qui découlerait plus d'une analyse de texte que d'une simple lecture froide sans réflexion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.61766238e-04,   1.19746421e-03,   3.16004521e-05, ...,\n",
       "          1.76047431e-05,   9.05940443e-04,   1.55366475e-04],\n",
       "       [ -2.24869185e-04,  -5.35864935e-04,  -1.40926674e-05, ...,\n",
       "         -1.47713398e-05,  -4.93414191e-04,  -1.16866029e-04]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD to 100 features (common value for LSA)\n",
    "lsa_tr = TruncatedSVD(n_components=100)\n",
    "train_lsa = lsa_tr.fit(train_tfidf)\n",
    "train_lsa.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificateurs\n",
    "\n",
    "Désormais, nous avons des features, certes simples, mais qui tente de décrire au mieux nos reviews. Nous allons à présent entraîner un classificateur afin d'obtenir un modèle mathématique qui puisse classifier nos reviews  Nous allons essayer l'une des techniques les plus connue, la régression logistique, afin d'obtenir une première baseline sur laquelle nous pourrons nous baser afin d'apporter des amélioration.\n",
    "\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup input train and validation as text only\n",
    "train_x = train[\"review_content\"]\n",
    "val_x = val[\"review_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline setup for simple classification\n",
    "lr_clf_pip = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LogisticRegression(max_iter=1000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6440424384103578"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression with default values for training\n",
    "lr_clf = lr_clf_pip.fit(train_x, train_y)\n",
    "\n",
    "# Prediction on validation set\n",
    "val_y_hat = lr_clf.predict(val_x)\n",
    "\n",
    "# Validation set score\n",
    "roc_auc_score(val_y_true, val_y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.501402625427\n"
     ]
    }
   ],
   "source": [
    "# Comparison to simple results such as random or only ones results\n",
    "print(roc_auc_score(val_y_true, [1]*len(val_y_true)))\n",
    "from random import *\n",
    "randBinList = lambda n: [randint(0,1) for b in range(1,n+1)]\n",
    "\n",
    "print(roc_auc_score(val_y_true, randBinList(len(val_y_true))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semblerait que notre modèle uniquement basé sur le texte semble apporter une plus value sur une classification aléatoire des review. Avec une performance proche des 65%, il est encourageant de penser que, potentiellement, d'autres classificaters, des features NLP plus travaillées et une investigation plus approfondies sur les paramètres de classifications pourront améliorer les performances actuelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_clf_pip = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('lsa', TruncatedSVD(n_components=1000)),\n",
    "                     ('clf', LogisticRegression(max_iter=10000))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63190073727746809"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eval_class(lr_clf_pip, train_x, train_y, val_x, val_y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Contrairement aux premières intuitions, il semble que LSA n'améliore pas la précision.\n",
    "En regardant notre analyse du dataset faite précédemment, on remarque aussi que la plupart des produits n'ont qu'une seul review et que, par conséquent, il semblerait normal que les reviews aient des sujets assez différents. Cependant, après plusieurs essais, il se trouve que le training et SVD soit assez sensible à plusieurs hyper-paramètres et mériterait peut être de plus longues explorations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark autres classificateurs\n",
    "LogisticRegression n'est pas la seul solution en terme de classificateur. Il semble raisonnable de faire une comparaison avec les classificateurs suivants :\n",
    "- Gaussian Naive Baysian\n",
    "- Nearest Neighbors\n",
    "- Random Forest\n",
    "- Decision Tree\n",
    "- Linear Singular Vector Machine (lsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipelines\n",
    "pipelines = [\n",
    "(\"gnb_clf_pip\" , Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('todensearray', SparseMatrixToDenseArray()),\n",
    "                     ('clf', GaussianNB())])),\n",
    "(\"knn_clf_pip\" , Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier())])),\n",
    "(\"dt_clf_pip\" ,  Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', DecisionTreeClassifier())])),\n",
    "(\"rf_clf_pip\" , Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', RandomForestClassifier())])),\n",
    "(\"lsvm_clf_pip\" , Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LinearSVC())]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing gnb_clf_pip ...\n",
      "computing knn_clf_pip ...\n",
      "computing dt_clf_pip ...\n",
      "computing rf_clf_pip ...\n",
      "computing lsvm_clf_pip ...\n"
     ]
    }
   ],
   "source": [
    "eval_class = []\n",
    "# Training and evaluation\n",
    "for pip_name, pip_obj in pipelines :\n",
    "    print(\"computing \" + pip_name + \" ...\")\n",
    "    eval = train_eval_class(pip_obj,train_x, train_y, val_x, val_y_true)             \n",
    "    eval_class.append([pip_name, eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>eval_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gnb_clf_pip</td>\n",
       "      <td>0.55324402086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn_clf_pip</td>\n",
       "      <td>0.53784840856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dt_clf_pip</td>\n",
       "      <td>0.590718395972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf_clf_pip</td>\n",
       "      <td>0.625496313613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lsvm_clf_pip</td>\n",
       "      <td>0.635382125517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     classifier      eval_score\n",
       "0   gnb_clf_pip   0.55324402086\n",
       "1   knn_clf_pip   0.53784840856\n",
       "2    dt_clf_pip  0.590718395972\n",
       "3    rf_clf_pip  0.625496313613\n",
       "4  lsvm_clf_pip  0.635382125517"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifiers comparison on evaluation set\n",
    "eval_class_np = np.array(eval_class)\n",
    "pd.DataFrame({\"classifier\":eval_class_np[:,0], \"eval_score\":eval_class_np[:,1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ensemble des résultats semblent proches et en tout cas en dessous de la régression logistique . Cependant, ces différents classifiers peuvent être optimisé en ce qui concerne les hyper-paramètres. Cependant, on peut déjà éliminer Gaussian Naive Bayes et K Nearest Neighbors ( tdlr : Dans le cas de KNN, nous avons testé avec différentes valeurs de K, sans succès au niveau de la précision).\n",
    "\n",
    "Une investigation intéressante, serait l'utilisation de LSA pour ces autres classificateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53404064017263075"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## KNN with LSA\n",
    "knn_clf_pip =  Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', KNeighborsClassifier(n_neighbors=10))])\n",
    "train_eval_class(knn_clf_pip,train_x, train_y, val_x, val_y_true) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipelines_lsa = [\n",
    "    (\"dt_clf_pip\" ,  Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('lsa', TruncatedSVD(n_components=100)),\n",
    "                     ('clf', DecisionTreeClassifier())])),\n",
    "    (\"rf_clf_pip\" , Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('lsa', TruncatedSVD(n_components=100)),\n",
    "                     ('clf', RandomForestClassifier())])),\n",
    "    (\"lsvm_clf_pip\" , Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('lsa', TruncatedSVD(n_components=100)),\n",
    "                     ('clf', LinearSVC())]))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing dt_clf_pip ...\n",
      "computing rf_clf_pip ...\n",
      "computing lsvm_clf_pip ...\n"
     ]
    }
   ],
   "source": [
    "eval_lsa_class = []\n",
    "# Training and evaluation\n",
    "for pip_name, pip_obj in pipelines_lsa :\n",
    "    print(\"computing \" + pip_name + \" ...\")\n",
    "    eval = train_eval_class(pip_obj,train_x, train_y, val_x, val_y_true)             \n",
    "    eval_lsa_class.append([pip_name, eval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>eval_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt_clf_pip</td>\n",
       "      <td>0.582103938141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf_clf_pip</td>\n",
       "      <td>0.59020589822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsvm_clf_pip</td>\n",
       "      <td>0.602833123539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     classifier      eval_score\n",
       "0    dt_clf_pip  0.582103938141\n",
       "1    rf_clf_pip   0.59020589822\n",
       "2  lsvm_clf_pip  0.602833123539"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Comparison classifiers with LSA on evaluation set\n",
    "eval_lsa_class_np = np.array(eval_lsa_class)\n",
    "pd.DataFrame({\"classifier\":eval_lsa_class_np[:,0], \"eval_score\":eval_lsa_class_np[:,1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observé jusqu'à présent les limitations du contenu de la review avec de classifiers non-optimisé au niveau des hyper-paramètres. Cependant, nous n'avons pas pris en compte d'autres facteurs qui puissent paraître important tel que :\n",
    "- La lisibilité et la facilité de lecture. Une review trop complexe ou illisible ne sera que peu utile.\n",
    "- Le titre. Il semble important d'attirer l'attention sur une review spécifique avec un titre accrocheur\n",
    "    \n",
    "Dans les prochaines sections, nous allon tenter d'utilisé ces features potentiels et les combiner à nos features actuelles.\n",
    "\n",
    "### Title analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_content_pip_clf = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('title', Pipeline([\n",
    "            ('select', ItemSelector(key=\"review_title\")),\n",
    "            ('transform', TfidfVectorizer())\n",
    "        ])),\n",
    "        ('content', Pipeline([\n",
    "            ('select', ItemSelector(key=\"review_content\")),\n",
    "            ('transform', TfidfVectorizer())\n",
    "        ]))\n",
    "    ])),\n",
    "    ('clf', LogisticRegression(max_iter=3000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65313073188275494"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eval_class(title_content_pip_clf, train, train_y, val, val_y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque une certaines améliorations en ajoutant cette feature. \n",
    "\n",
    "### Text Statistics\n",
    "\n",
    "Concernant la facilité de lecture ou la lisibilité , ils découlent des même variables : le nombre de mot, de phrases et de caractère. Nous pouvont donc ajouter ces composant au sein de notre pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_content_pip_clf = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('title', Pipeline([\n",
    "            ('select', ItemSelector(key=\"review_title\")),\n",
    "            ('transform', TfidfVectorizer())\n",
    "        ])),\n",
    "        ('content', Pipeline([\n",
    "            ('select', ItemSelector(key=\"review_content\")),\n",
    "            ('transform', TfidfVectorizer())\n",
    "        ])),\n",
    "         ('text_stats', Pipeline([\n",
    "                ('select', ItemSelector(key='review_content')),\n",
    "                ('stats', TextStats()),  \n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ]))\n",
    "    ])),\n",
    "    ('clf', LogisticRegression(max_iter=3000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65366840496313605"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eval_class(title_content_pip_clf, train, train_y, val, val_y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ajout de features supplémentaire, comme prédit par notre analyse de la correlation, n'apporte que très peu d'amélioration. \n",
    "\n",
    "### Méthodes non-linéaire\n",
    "Notre teste final en ce qui concerne les classificateurs sera l'utilisation d'un classificateur non-linéaire: SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without LSA, kernel : poly\n",
    "title_content_pip_clf = Pipeline([\n",
    "    ('title', Pipeline([\n",
    "            ('select', ItemSelector(key=\"review_title\")),\n",
    "            ('transform', TfidfVectorizer())\n",
    "    ])),\n",
    "    ('clf', SVC(C=5, ))\n",
    "])\n",
    "train_eval_class(title_content_pip_clf, train, train_y, val, val_y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5317155187915843"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With LSA; kernel rtbf\n",
    "title_content_pip_clf = Pipeline([\n",
    "    ('title', Pipeline([\n",
    "            ('select', ItemSelector(key=\"review_title\")),\n",
    "            ('transform', TfidfVectorizer()),\n",
    "            ('svd', TruncatedSVD(n_components=100))\n",
    "    ])),\n",
    "    ('clf', SVC(C=15))\n",
    "])\n",
    "train_eval_class(title_content_pip_clf, train, train_y, val, val_y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats avec des kernel non-linéaire pour SVM semblent peu convaincant (après plusieurs essais).\n",
    "\n",
    "### Cross-Validation et optimisation des hyper-paramètres\n",
    "\n",
    "Il semblerait que nous ayons utilisé et déduit un bon nombre de features possibles et une méthode de classification correcte. \n",
    "Désormais, il semblerait judicieux d'optimizer LogisticRegession classifier et d'ajouter des méthodes de cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classifier pipeline\n",
    "clf_pip = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('title', Pipeline([\n",
    "            ('select', ItemSelector(key=\"review_title\")),\n",
    "            ('tfidf', TfidfVectorizer())\n",
    "        ])),\n",
    "        ('content', Pipeline([\n",
    "            ('select', ItemSelector(key=\"review_content\")),\n",
    "            ('tfidf', TfidfVectorizer())\n",
    "        ])),\n",
    "         ('text_stats', Pipeline([\n",
    "                ('select', ItemSelector(key='review_content')),\n",
    "                ('stats', TextStats()),  \n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "    ])),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression parmeters\n",
    "parameters = {\n",
    "    'union__content__tfidf__use_idf': (True, False),\n",
    "    'union__content__tfidf__smooth_idf':(True, False),\n",
    "    'union__content__tfidf__sublinear_tf':(True, False),\n",
    "    'union__content__tfidf__norm': ('l1', 'l2', None),\n",
    "    'clf__penalty': ('l1','l2')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grid Search with 5-fold cross-validation ()\n",
    "grid_search = GridSearchCV(clf_pip, parameters, scoring='roc_auc', cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('union', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('title', Pipeline(steps=[('select', ItemSelector(key='review_title')), ('tfidf', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=1, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'clf__penalty': ('l1', 'l2'), 'union__content__tfidf__smooth_idf': (True, False), 'union__content__tfidf__use_idf': (True, False), 'union__content__tfidf__norm': ('l1', 'l2', None), 'union__content__tfidf__sublinear_tf': (True, False)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__penalty': 'l2', 'union__content__tfidf__use_idf': True, 'union__content__tfidf__smooth_idf': True, 'union__content__tfidf__sublinear_tf': True, 'union__content__tfidf__norm': 'l2'}\n",
      "0.712048723785\n"
     ]
    }
   ],
   "source": [
    "# best parameters results and score\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <th>param_union__content__tfidf__norm</th>\n",
       "      <th>param_union__content__tfidf__smooth_idf</th>\n",
       "      <th>param_union__content__tfidf__sublinear_tf</th>\n",
       "      <th>param_union__content__tfidf__use_idf</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.227974</td>\n",
       "      <td>1.483329</td>\n",
       "      <td>0.684880</td>\n",
       "      <td>0.740248</td>\n",
       "      <td>l1</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692322</td>\n",
       "      <td>0.738040</td>\n",
       "      <td>0.689004</td>\n",
       "      <td>0.739512</td>\n",
       "      <td>0.686958</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>6.296197</td>\n",
       "      <td>0.034365</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.631523</td>\n",
       "      <td>1.565365</td>\n",
       "      <td>0.682036</td>\n",
       "      <td>0.735997</td>\n",
       "      <td>l1</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688380</td>\n",
       "      <td>0.733947</td>\n",
       "      <td>0.687249</td>\n",
       "      <td>0.735341</td>\n",
       "      <td>0.683635</td>\n",
       "      <td>0.735345</td>\n",
       "      <td>10.800199</td>\n",
       "      <td>0.114739</td>\n",
       "      <td>0.005687</td>\n",
       "      <td>0.001542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.625373</td>\n",
       "      <td>1.483654</td>\n",
       "      <td>0.684700</td>\n",
       "      <td>0.740137</td>\n",
       "      <td>l1</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692127</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>0.689090</td>\n",
       "      <td>0.739291</td>\n",
       "      <td>0.686518</td>\n",
       "      <td>0.739841</td>\n",
       "      <td>6.760962</td>\n",
       "      <td>0.047188</td>\n",
       "      <td>0.006008</td>\n",
       "      <td>0.001486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.754451</td>\n",
       "      <td>1.482417</td>\n",
       "      <td>0.681624</td>\n",
       "      <td>0.735649</td>\n",
       "      <td>l1</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687967</td>\n",
       "      <td>0.733625</td>\n",
       "      <td>0.687015</td>\n",
       "      <td>0.734912</td>\n",
       "      <td>0.683079</td>\n",
       "      <td>0.735058</td>\n",
       "      <td>10.234684</td>\n",
       "      <td>0.041004</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.001535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85.488874</td>\n",
       "      <td>1.522564</td>\n",
       "      <td>0.684818</td>\n",
       "      <td>0.740163</td>\n",
       "      <td>l1</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692273</td>\n",
       "      <td>0.737951</td>\n",
       "      <td>0.688922</td>\n",
       "      <td>0.739445</td>\n",
       "      <td>0.686919</td>\n",
       "      <td>0.739804</td>\n",
       "      <td>9.765571</td>\n",
       "      <td>0.081701</td>\n",
       "      <td>0.006036</td>\n",
       "      <td>0.001506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>91.851646</td>\n",
       "      <td>1.553726</td>\n",
       "      <td>0.682028</td>\n",
       "      <td>0.735996</td>\n",
       "      <td>l1</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688379</td>\n",
       "      <td>0.733946</td>\n",
       "      <td>0.687253</td>\n",
       "      <td>0.735341</td>\n",
       "      <td>0.683634</td>\n",
       "      <td>0.735345</td>\n",
       "      <td>10.544492</td>\n",
       "      <td>0.097727</td>\n",
       "      <td>0.005694</td>\n",
       "      <td>0.001542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87.040554</td>\n",
       "      <td>1.570476</td>\n",
       "      <td>0.684657</td>\n",
       "      <td>0.740057</td>\n",
       "      <td>l1</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.692074</td>\n",
       "      <td>0.737916</td>\n",
       "      <td>0.689017</td>\n",
       "      <td>0.739225</td>\n",
       "      <td>0.686497</td>\n",
       "      <td>0.739757</td>\n",
       "      <td>9.689095</td>\n",
       "      <td>0.053234</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>0.001486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95.705267</td>\n",
       "      <td>1.504373</td>\n",
       "      <td>0.681628</td>\n",
       "      <td>0.735649</td>\n",
       "      <td>l1</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687965</td>\n",
       "      <td>0.733625</td>\n",
       "      <td>0.687015</td>\n",
       "      <td>0.734912</td>\n",
       "      <td>0.683081</td>\n",
       "      <td>0.735058</td>\n",
       "      <td>8.128833</td>\n",
       "      <td>0.039917</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.001535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>162.596211</td>\n",
       "      <td>1.563034</td>\n",
       "      <td>0.701026</td>\n",
       "      <td>0.791184</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705790</td>\n",
       "      <td>0.790052</td>\n",
       "      <td>0.710384</td>\n",
       "      <td>0.788982</td>\n",
       "      <td>0.702574</td>\n",
       "      <td>0.791762</td>\n",
       "      <td>13.599501</td>\n",
       "      <td>0.060125</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>168.201494</td>\n",
       "      <td>1.562196</td>\n",
       "      <td>0.699318</td>\n",
       "      <td>0.772625</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703634</td>\n",
       "      <td>0.771500</td>\n",
       "      <td>0.707879</td>\n",
       "      <td>0.770177</td>\n",
       "      <td>0.701354</td>\n",
       "      <td>0.773197</td>\n",
       "      <td>18.432759</td>\n",
       "      <td>0.069059</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>0.001676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>169.481451</td>\n",
       "      <td>1.563772</td>\n",
       "      <td>0.700833</td>\n",
       "      <td>0.790332</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705788</td>\n",
       "      <td>0.789147</td>\n",
       "      <td>0.710111</td>\n",
       "      <td>0.788221</td>\n",
       "      <td>0.702291</td>\n",
       "      <td>0.790872</td>\n",
       "      <td>19.351206</td>\n",
       "      <td>0.043090</td>\n",
       "      <td>0.007221</td>\n",
       "      <td>0.001498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>155.601933</td>\n",
       "      <td>1.620136</td>\n",
       "      <td>0.698552</td>\n",
       "      <td>0.770547</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702917</td>\n",
       "      <td>0.769467</td>\n",
       "      <td>0.707125</td>\n",
       "      <td>0.768158</td>\n",
       "      <td>0.700843</td>\n",
       "      <td>0.771168</td>\n",
       "      <td>18.036368</td>\n",
       "      <td>0.049416</td>\n",
       "      <td>0.006720</td>\n",
       "      <td>0.001583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>169.208500</td>\n",
       "      <td>1.614495</td>\n",
       "      <td>0.701020</td>\n",
       "      <td>0.790914</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705815</td>\n",
       "      <td>0.789783</td>\n",
       "      <td>0.710312</td>\n",
       "      <td>0.788687</td>\n",
       "      <td>0.702553</td>\n",
       "      <td>0.791518</td>\n",
       "      <td>21.270948</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.001507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>164.377027</td>\n",
       "      <td>1.589957</td>\n",
       "      <td>0.699333</td>\n",
       "      <td>0.772625</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703633</td>\n",
       "      <td>0.771500</td>\n",
       "      <td>0.707880</td>\n",
       "      <td>0.770177</td>\n",
       "      <td>0.701354</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>16.367125</td>\n",
       "      <td>0.043901</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.001676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>160.879491</td>\n",
       "      <td>1.601155</td>\n",
       "      <td>0.700811</td>\n",
       "      <td>0.790086</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705755</td>\n",
       "      <td>0.788905</td>\n",
       "      <td>0.710066</td>\n",
       "      <td>0.787961</td>\n",
       "      <td>0.702299</td>\n",
       "      <td>0.790653</td>\n",
       "      <td>16.114625</td>\n",
       "      <td>0.037720</td>\n",
       "      <td>0.007213</td>\n",
       "      <td>0.001503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>155.685509</td>\n",
       "      <td>1.561606</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.770547</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702917</td>\n",
       "      <td>0.769466</td>\n",
       "      <td>0.707124</td>\n",
       "      <td>0.768158</td>\n",
       "      <td>0.700844</td>\n",
       "      <td>0.771168</td>\n",
       "      <td>16.542563</td>\n",
       "      <td>0.046796</td>\n",
       "      <td>0.006738</td>\n",
       "      <td>0.001583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>198.651671</td>\n",
       "      <td>1.568056</td>\n",
       "      <td>0.661505</td>\n",
       "      <td>0.993114</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658843</td>\n",
       "      <td>0.993073</td>\n",
       "      <td>0.667767</td>\n",
       "      <td>0.993054</td>\n",
       "      <td>0.667996</td>\n",
       "      <td>0.993161</td>\n",
       "      <td>37.440139</td>\n",
       "      <td>0.046954</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>301.424671</td>\n",
       "      <td>1.518912</td>\n",
       "      <td>0.698496</td>\n",
       "      <td>0.890162</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705059</td>\n",
       "      <td>0.889704</td>\n",
       "      <td>0.708131</td>\n",
       "      <td>0.888875</td>\n",
       "      <td>0.698898</td>\n",
       "      <td>0.889706</td>\n",
       "      <td>36.048994</td>\n",
       "      <td>0.028334</td>\n",
       "      <td>0.007401</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202.810445</td>\n",
       "      <td>1.530506</td>\n",
       "      <td>0.661231</td>\n",
       "      <td>0.993123</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658194</td>\n",
       "      <td>0.993066</td>\n",
       "      <td>0.667246</td>\n",
       "      <td>0.993082</td>\n",
       "      <td>0.667369</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>32.022203</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>284.140081</td>\n",
       "      <td>1.590017</td>\n",
       "      <td>0.696592</td>\n",
       "      <td>0.891470</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703907</td>\n",
       "      <td>0.890988</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.890251</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>30.695872</td>\n",
       "      <td>0.081746</td>\n",
       "      <td>0.007165</td>\n",
       "      <td>0.000958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>196.308717</td>\n",
       "      <td>1.567041</td>\n",
       "      <td>0.661270</td>\n",
       "      <td>0.993292</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658757</td>\n",
       "      <td>0.993252</td>\n",
       "      <td>0.667393</td>\n",
       "      <td>0.993230</td>\n",
       "      <td>0.667564</td>\n",
       "      <td>0.993351</td>\n",
       "      <td>34.962922</td>\n",
       "      <td>0.047893</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>305.739686</td>\n",
       "      <td>1.567282</td>\n",
       "      <td>0.698499</td>\n",
       "      <td>0.890162</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705010</td>\n",
       "      <td>0.889704</td>\n",
       "      <td>0.708139</td>\n",
       "      <td>0.888875</td>\n",
       "      <td>0.698915</td>\n",
       "      <td>0.889706</td>\n",
       "      <td>34.571807</td>\n",
       "      <td>0.107082</td>\n",
       "      <td>0.007386</td>\n",
       "      <td>0.000952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>199.733070</td>\n",
       "      <td>1.548803</td>\n",
       "      <td>0.660916</td>\n",
       "      <td>0.993300</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658007</td>\n",
       "      <td>0.993245</td>\n",
       "      <td>0.666673</td>\n",
       "      <td>0.993273</td>\n",
       "      <td>0.667271</td>\n",
       "      <td>0.993369</td>\n",
       "      <td>26.748914</td>\n",
       "      <td>0.039035</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>257.024443</td>\n",
       "      <td>1.454620</td>\n",
       "      <td>0.696592</td>\n",
       "      <td>0.891471</td>\n",
       "      <td>l1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l1', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703897</td>\n",
       "      <td>0.890988</td>\n",
       "      <td>0.705413</td>\n",
       "      <td>0.890251</td>\n",
       "      <td>0.696298</td>\n",
       "      <td>0.890958</td>\n",
       "      <td>25.248289</td>\n",
       "      <td>0.068906</td>\n",
       "      <td>0.007164</td>\n",
       "      <td>0.000958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11.549936</td>\n",
       "      <td>1.552076</td>\n",
       "      <td>0.686554</td>\n",
       "      <td>0.823898</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693641</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.690840</td>\n",
       "      <td>0.829522</td>\n",
       "      <td>0.687299</td>\n",
       "      <td>0.811986</td>\n",
       "      <td>0.404963</td>\n",
       "      <td>0.055687</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.006217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10.568727</td>\n",
       "      <td>1.465930</td>\n",
       "      <td>0.680310</td>\n",
       "      <td>0.804509</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686589</td>\n",
       "      <td>0.812174</td>\n",
       "      <td>0.684539</td>\n",
       "      <td>0.790225</td>\n",
       "      <td>0.680965</td>\n",
       "      <td>0.805462</td>\n",
       "      <td>0.406666</td>\n",
       "      <td>0.011379</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.008376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.745032</td>\n",
       "      <td>1.493622</td>\n",
       "      <td>0.686506</td>\n",
       "      <td>0.824630</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693591</td>\n",
       "      <td>0.827018</td>\n",
       "      <td>0.690594</td>\n",
       "      <td>0.828276</td>\n",
       "      <td>0.687665</td>\n",
       "      <td>0.822732</td>\n",
       "      <td>0.409550</td>\n",
       "      <td>0.026512</td>\n",
       "      <td>0.005469</td>\n",
       "      <td>0.003167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.903677</td>\n",
       "      <td>1.433741</td>\n",
       "      <td>0.679889</td>\n",
       "      <td>0.804767</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685207</td>\n",
       "      <td>0.803468</td>\n",
       "      <td>0.683229</td>\n",
       "      <td>0.781214</td>\n",
       "      <td>0.681356</td>\n",
       "      <td>0.812356</td>\n",
       "      <td>0.718872</td>\n",
       "      <td>0.075165</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.012358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.116652</td>\n",
       "      <td>1.407801</td>\n",
       "      <td>0.686312</td>\n",
       "      <td>0.821487</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693865</td>\n",
       "      <td>0.827775</td>\n",
       "      <td>0.690553</td>\n",
       "      <td>0.825776</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.826927</td>\n",
       "      <td>0.372363</td>\n",
       "      <td>0.046577</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.008870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.987841</td>\n",
       "      <td>1.435068</td>\n",
       "      <td>0.680310</td>\n",
       "      <td>0.804509</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686589</td>\n",
       "      <td>0.812174</td>\n",
       "      <td>0.684539</td>\n",
       "      <td>0.790225</td>\n",
       "      <td>0.680965</td>\n",
       "      <td>0.805462</td>\n",
       "      <td>0.111057</td>\n",
       "      <td>0.057741</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.008376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9.081049</td>\n",
       "      <td>1.438202</td>\n",
       "      <td>0.686017</td>\n",
       "      <td>0.823496</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693360</td>\n",
       "      <td>0.826075</td>\n",
       "      <td>0.689775</td>\n",
       "      <td>0.826707</td>\n",
       "      <td>0.686629</td>\n",
       "      <td>0.812272</td>\n",
       "      <td>0.136459</td>\n",
       "      <td>0.078249</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.005698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8.803264</td>\n",
       "      <td>1.385986</td>\n",
       "      <td>0.679889</td>\n",
       "      <td>0.804767</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.685207</td>\n",
       "      <td>0.803468</td>\n",
       "      <td>0.683229</td>\n",
       "      <td>0.781214</td>\n",
       "      <td>0.681356</td>\n",
       "      <td>0.812356</td>\n",
       "      <td>0.440704</td>\n",
       "      <td>0.008356</td>\n",
       "      <td>0.004337</td>\n",
       "      <td>0.012358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.893873</td>\n",
       "      <td>1.425494</td>\n",
       "      <td>0.712049</td>\n",
       "      <td>0.900930</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717455</td>\n",
       "      <td>0.901646</td>\n",
       "      <td>0.719335</td>\n",
       "      <td>0.894059</td>\n",
       "      <td>0.713699</td>\n",
       "      <td>0.903550</td>\n",
       "      <td>0.569852</td>\n",
       "      <td>0.027323</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>0.003497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>9.168308</td>\n",
       "      <td>1.394452</td>\n",
       "      <td>0.708145</td>\n",
       "      <td>0.864969</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713310</td>\n",
       "      <td>0.864153</td>\n",
       "      <td>0.715611</td>\n",
       "      <td>0.864961</td>\n",
       "      <td>0.709577</td>\n",
       "      <td>0.865795</td>\n",
       "      <td>0.425130</td>\n",
       "      <td>0.023332</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>0.000519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9.240817</td>\n",
       "      <td>1.382454</td>\n",
       "      <td>0.711653</td>\n",
       "      <td>0.899755</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717483</td>\n",
       "      <td>0.901070</td>\n",
       "      <td>0.719360</td>\n",
       "      <td>0.902018</td>\n",
       "      <td>0.713066</td>\n",
       "      <td>0.901396</td>\n",
       "      <td>0.350147</td>\n",
       "      <td>0.054763</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.003483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>9.381712</td>\n",
       "      <td>1.393562</td>\n",
       "      <td>0.706894</td>\n",
       "      <td>0.861707</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712276</td>\n",
       "      <td>0.860441</td>\n",
       "      <td>0.714394</td>\n",
       "      <td>0.861697</td>\n",
       "      <td>0.708125</td>\n",
       "      <td>0.862363</td>\n",
       "      <td>0.136298</td>\n",
       "      <td>0.018397</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>8.851771</td>\n",
       "      <td>1.376776</td>\n",
       "      <td>0.712047</td>\n",
       "      <td>0.903789</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717146</td>\n",
       "      <td>0.903512</td>\n",
       "      <td>0.719831</td>\n",
       "      <td>0.904748</td>\n",
       "      <td>0.713206</td>\n",
       "      <td>0.902602</td>\n",
       "      <td>0.548195</td>\n",
       "      <td>0.034357</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.000712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>9.416939</td>\n",
       "      <td>1.414790</td>\n",
       "      <td>0.708145</td>\n",
       "      <td>0.864969</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713310</td>\n",
       "      <td>0.864153</td>\n",
       "      <td>0.715611</td>\n",
       "      <td>0.864961</td>\n",
       "      <td>0.709577</td>\n",
       "      <td>0.865795</td>\n",
       "      <td>0.137832</td>\n",
       "      <td>0.066871</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>0.000519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8.675596</td>\n",
       "      <td>1.392779</td>\n",
       "      <td>0.711612</td>\n",
       "      <td>0.894824</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717458</td>\n",
       "      <td>0.899637</td>\n",
       "      <td>0.719269</td>\n",
       "      <td>0.892224</td>\n",
       "      <td>0.713473</td>\n",
       "      <td>0.883174</td>\n",
       "      <td>0.466359</td>\n",
       "      <td>0.067053</td>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.006848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>9.384932</td>\n",
       "      <td>1.417474</td>\n",
       "      <td>0.706894</td>\n",
       "      <td>0.861707</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712276</td>\n",
       "      <td>0.860441</td>\n",
       "      <td>0.714394</td>\n",
       "      <td>0.861697</td>\n",
       "      <td>0.708125</td>\n",
       "      <td>0.862363</td>\n",
       "      <td>0.154530</td>\n",
       "      <td>0.050099</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20.388604</td>\n",
       "      <td>1.470098</td>\n",
       "      <td>0.657686</td>\n",
       "      <td>0.995697</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654888</td>\n",
       "      <td>0.996046</td>\n",
       "      <td>0.668716</td>\n",
       "      <td>0.994942</td>\n",
       "      <td>0.670470</td>\n",
       "      <td>0.994292</td>\n",
       "      <td>1.387123</td>\n",
       "      <td>0.060299</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>16.851196</td>\n",
       "      <td>1.456261</td>\n",
       "      <td>0.703458</td>\n",
       "      <td>0.965607</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709562</td>\n",
       "      <td>0.966442</td>\n",
       "      <td>0.710852</td>\n",
       "      <td>0.963240</td>\n",
       "      <td>0.705382</td>\n",
       "      <td>0.966758</td>\n",
       "      <td>1.768423</td>\n",
       "      <td>0.047552</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.001241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>17.472830</td>\n",
       "      <td>1.439471</td>\n",
       "      <td>0.678094</td>\n",
       "      <td>0.988479</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670010</td>\n",
       "      <td>0.992782</td>\n",
       "      <td>0.676019</td>\n",
       "      <td>0.992690</td>\n",
       "      <td>0.691380</td>\n",
       "      <td>0.984004</td>\n",
       "      <td>0.965489</td>\n",
       "      <td>0.064409</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>0.003891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>19.515021</td>\n",
       "      <td>1.541557</td>\n",
       "      <td>0.702375</td>\n",
       "      <td>0.959863</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.967103</td>\n",
       "      <td>0.708329</td>\n",
       "      <td>0.967246</td>\n",
       "      <td>0.703272</td>\n",
       "      <td>0.966760</td>\n",
       "      <td>1.277149</td>\n",
       "      <td>0.110016</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.013749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>19.960407</td>\n",
       "      <td>1.623710</td>\n",
       "      <td>0.662320</td>\n",
       "      <td>0.994795</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661323</td>\n",
       "      <td>0.995104</td>\n",
       "      <td>0.668669</td>\n",
       "      <td>0.995027</td>\n",
       "      <td>0.674349</td>\n",
       "      <td>0.993350</td>\n",
       "      <td>2.309415</td>\n",
       "      <td>0.391801</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>0.001215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>21.939739</td>\n",
       "      <td>2.265431</td>\n",
       "      <td>0.703458</td>\n",
       "      <td>0.965607</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709562</td>\n",
       "      <td>0.966442</td>\n",
       "      <td>0.710852</td>\n",
       "      <td>0.963240</td>\n",
       "      <td>0.705382</td>\n",
       "      <td>0.966758</td>\n",
       "      <td>2.540169</td>\n",
       "      <td>0.465775</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.001241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20.528671</td>\n",
       "      <td>1.670840</td>\n",
       "      <td>0.682242</td>\n",
       "      <td>0.986497</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676567</td>\n",
       "      <td>0.990989</td>\n",
       "      <td>0.691876</td>\n",
       "      <td>0.985131</td>\n",
       "      <td>0.678515</td>\n",
       "      <td>0.991730</td>\n",
       "      <td>1.872970</td>\n",
       "      <td>0.153124</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.004293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20.416519</td>\n",
       "      <td>1.228311</td>\n",
       "      <td>0.702375</td>\n",
       "      <td>0.959863</td>\n",
       "      <td>l2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{u'clf__penalty': u'l2', u'union__content__tfi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.967103</td>\n",
       "      <td>0.708329</td>\n",
       "      <td>0.967246</td>\n",
       "      <td>0.703272</td>\n",
       "      <td>0.966760</td>\n",
       "      <td>1.965618</td>\n",
       "      <td>0.097668</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.013749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       85.227974         1.483329         0.684880          0.740248   \n",
       "1       92.631523         1.565365         0.682036          0.735997   \n",
       "2       89.625373         1.483654         0.684700          0.740137   \n",
       "3       91.754451         1.482417         0.681624          0.735649   \n",
       "4       85.488874         1.522564         0.684818          0.740163   \n",
       "5       91.851646         1.553726         0.682028          0.735996   \n",
       "6       87.040554         1.570476         0.684657          0.740057   \n",
       "7       95.705267         1.504373         0.681628          0.735649   \n",
       "8      162.596211         1.563034         0.701026          0.791184   \n",
       "9      168.201494         1.562196         0.699318          0.772625   \n",
       "10     169.481451         1.563772         0.700833          0.790332   \n",
       "11     155.601933         1.620136         0.698552          0.770547   \n",
       "12     169.208500         1.614495         0.701020          0.790914   \n",
       "13     164.377027         1.589957         0.699333          0.772625   \n",
       "14     160.879491         1.601155         0.700811          0.790086   \n",
       "15     155.685509         1.561606         0.698529          0.770547   \n",
       "16     198.651671         1.568056         0.661505          0.993114   \n",
       "17     301.424671         1.518912         0.698496          0.890162   \n",
       "18     202.810445         1.530506         0.661231          0.993123   \n",
       "19     284.140081         1.590017         0.696592          0.891470   \n",
       "20     196.308717         1.567041         0.661270          0.993292   \n",
       "21     305.739686         1.567282         0.698499          0.890162   \n",
       "22     199.733070         1.548803         0.660916          0.993300   \n",
       "23     257.024443         1.454620         0.696592          0.891471   \n",
       "24      11.549936         1.552076         0.686554          0.823898   \n",
       "25      10.568727         1.465930         0.680310          0.804509   \n",
       "26      10.745032         1.493622         0.686506          0.824630   \n",
       "27       9.903677         1.433741         0.679889          0.804767   \n",
       "28       9.116652         1.407801         0.686312          0.821487   \n",
       "29       8.987841         1.435068         0.680310          0.804509   \n",
       "30       9.081049         1.438202         0.686017          0.823496   \n",
       "31       8.803264         1.385986         0.679889          0.804767   \n",
       "32       8.893873         1.425494         0.712049          0.900930   \n",
       "33       9.168308         1.394452         0.708145          0.864969   \n",
       "34       9.240817         1.382454         0.711653          0.899755   \n",
       "35       9.381712         1.393562         0.706894          0.861707   \n",
       "36       8.851771         1.376776         0.712047          0.903789   \n",
       "37       9.416939         1.414790         0.708145          0.864969   \n",
       "38       8.675596         1.392779         0.711612          0.894824   \n",
       "39       9.384932         1.417474         0.706894          0.861707   \n",
       "40      20.388604         1.470098         0.657686          0.995697   \n",
       "41      16.851196         1.456261         0.703458          0.965607   \n",
       "42      17.472830         1.439471         0.678094          0.988479   \n",
       "43      19.515021         1.541557         0.702375          0.959863   \n",
       "44      19.960407         1.623710         0.662320          0.994795   \n",
       "45      21.939739         2.265431         0.703458          0.965607   \n",
       "46      20.528671         1.670840         0.682242          0.986497   \n",
       "47      20.416519         1.228311         0.702375          0.959863   \n",
       "\n",
       "   param_clf__penalty param_union__content__tfidf__norm  \\\n",
       "0                  l1                                l1   \n",
       "1                  l1                                l1   \n",
       "2                  l1                                l1   \n",
       "3                  l1                                l1   \n",
       "4                  l1                                l1   \n",
       "5                  l1                                l1   \n",
       "6                  l1                                l1   \n",
       "7                  l1                                l1   \n",
       "8                  l1                                l2   \n",
       "9                  l1                                l2   \n",
       "10                 l1                                l2   \n",
       "11                 l1                                l2   \n",
       "12                 l1                                l2   \n",
       "13                 l1                                l2   \n",
       "14                 l1                                l2   \n",
       "15                 l1                                l2   \n",
       "16                 l1                              None   \n",
       "17                 l1                              None   \n",
       "18                 l1                              None   \n",
       "19                 l1                              None   \n",
       "20                 l1                              None   \n",
       "21                 l1                              None   \n",
       "22                 l1                              None   \n",
       "23                 l1                              None   \n",
       "24                 l2                                l1   \n",
       "25                 l2                                l1   \n",
       "26                 l2                                l1   \n",
       "27                 l2                                l1   \n",
       "28                 l2                                l1   \n",
       "29                 l2                                l1   \n",
       "30                 l2                                l1   \n",
       "31                 l2                                l1   \n",
       "32                 l2                                l2   \n",
       "33                 l2                                l2   \n",
       "34                 l2                                l2   \n",
       "35                 l2                                l2   \n",
       "36                 l2                                l2   \n",
       "37                 l2                                l2   \n",
       "38                 l2                                l2   \n",
       "39                 l2                                l2   \n",
       "40                 l2                              None   \n",
       "41                 l2                              None   \n",
       "42                 l2                              None   \n",
       "43                 l2                              None   \n",
       "44                 l2                              None   \n",
       "45                 l2                              None   \n",
       "46                 l2                              None   \n",
       "47                 l2                              None   \n",
       "\n",
       "   param_union__content__tfidf__smooth_idf  \\\n",
       "0                                     True   \n",
       "1                                     True   \n",
       "2                                     True   \n",
       "3                                     True   \n",
       "4                                    False   \n",
       "5                                    False   \n",
       "6                                    False   \n",
       "7                                    False   \n",
       "8                                     True   \n",
       "9                                     True   \n",
       "10                                    True   \n",
       "11                                    True   \n",
       "12                                   False   \n",
       "13                                   False   \n",
       "14                                   False   \n",
       "15                                   False   \n",
       "16                                    True   \n",
       "17                                    True   \n",
       "18                                    True   \n",
       "19                                    True   \n",
       "20                                   False   \n",
       "21                                   False   \n",
       "22                                   False   \n",
       "23                                   False   \n",
       "24                                    True   \n",
       "25                                    True   \n",
       "26                                    True   \n",
       "27                                    True   \n",
       "28                                   False   \n",
       "29                                   False   \n",
       "30                                   False   \n",
       "31                                   False   \n",
       "32                                    True   \n",
       "33                                    True   \n",
       "34                                    True   \n",
       "35                                    True   \n",
       "36                                   False   \n",
       "37                                   False   \n",
       "38                                   False   \n",
       "39                                   False   \n",
       "40                                    True   \n",
       "41                                    True   \n",
       "42                                    True   \n",
       "43                                    True   \n",
       "44                                   False   \n",
       "45                                   False   \n",
       "46                                   False   \n",
       "47                                   False   \n",
       "\n",
       "   param_union__content__tfidf__sublinear_tf  \\\n",
       "0                                       True   \n",
       "1                                       True   \n",
       "2                                      False   \n",
       "3                                      False   \n",
       "4                                       True   \n",
       "5                                       True   \n",
       "6                                      False   \n",
       "7                                      False   \n",
       "8                                       True   \n",
       "9                                       True   \n",
       "10                                     False   \n",
       "11                                     False   \n",
       "12                                      True   \n",
       "13                                      True   \n",
       "14                                     False   \n",
       "15                                     False   \n",
       "16                                      True   \n",
       "17                                      True   \n",
       "18                                     False   \n",
       "19                                     False   \n",
       "20                                      True   \n",
       "21                                      True   \n",
       "22                                     False   \n",
       "23                                     False   \n",
       "24                                      True   \n",
       "25                                      True   \n",
       "26                                     False   \n",
       "27                                     False   \n",
       "28                                      True   \n",
       "29                                      True   \n",
       "30                                     False   \n",
       "31                                     False   \n",
       "32                                      True   \n",
       "33                                      True   \n",
       "34                                     False   \n",
       "35                                     False   \n",
       "36                                      True   \n",
       "37                                      True   \n",
       "38                                     False   \n",
       "39                                     False   \n",
       "40                                      True   \n",
       "41                                      True   \n",
       "42                                     False   \n",
       "43                                     False   \n",
       "44                                      True   \n",
       "45                                      True   \n",
       "46                                     False   \n",
       "47                                     False   \n",
       "\n",
       "   param_union__content__tfidf__use_idf  \\\n",
       "0                                  True   \n",
       "1                                 False   \n",
       "2                                  True   \n",
       "3                                 False   \n",
       "4                                  True   \n",
       "5                                 False   \n",
       "6                                  True   \n",
       "7                                 False   \n",
       "8                                  True   \n",
       "9                                 False   \n",
       "10                                 True   \n",
       "11                                False   \n",
       "12                                 True   \n",
       "13                                False   \n",
       "14                                 True   \n",
       "15                                False   \n",
       "16                                 True   \n",
       "17                                False   \n",
       "18                                 True   \n",
       "19                                False   \n",
       "20                                 True   \n",
       "21                                False   \n",
       "22                                 True   \n",
       "23                                False   \n",
       "24                                 True   \n",
       "25                                False   \n",
       "26                                 True   \n",
       "27                                False   \n",
       "28                                 True   \n",
       "29                                False   \n",
       "30                                 True   \n",
       "31                                False   \n",
       "32                                 True   \n",
       "33                                False   \n",
       "34                                 True   \n",
       "35                                False   \n",
       "36                                 True   \n",
       "37                                False   \n",
       "38                                 True   \n",
       "39                                False   \n",
       "40                                 True   \n",
       "41                                False   \n",
       "42                                 True   \n",
       "43                                False   \n",
       "44                                 True   \n",
       "45                                False   \n",
       "46                                 True   \n",
       "47                                False   \n",
       "\n",
       "                                               params       ...         \\\n",
       "0   {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "1   {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "2   {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "3   {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "4   {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "5   {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "6   {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "7   {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "8   {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "9   {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "10  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "11  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "12  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "13  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "14  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "15  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "16  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "17  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "18  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "19  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "20  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "21  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "22  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "23  {u'clf__penalty': u'l1', u'union__content__tfi...       ...          \n",
       "24  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "25  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "26  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "27  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "28  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "29  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "30  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "31  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "32  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "33  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "34  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "35  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "36  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "37  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "38  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "39  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "40  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "41  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "42  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "43  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "44  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "45  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "46  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "47  {u'clf__penalty': u'l2', u'union__content__tfi...       ...          \n",
       "\n",
       "    split2_test_score  split2_train_score  split3_test_score  \\\n",
       "0            0.692322            0.738040           0.689004   \n",
       "1            0.688380            0.733947           0.687249   \n",
       "2            0.692127            0.738002           0.689090   \n",
       "3            0.687967            0.733625           0.687015   \n",
       "4            0.692273            0.737951           0.688922   \n",
       "5            0.688379            0.733946           0.687253   \n",
       "6            0.692074            0.737916           0.689017   \n",
       "7            0.687965            0.733625           0.687015   \n",
       "8            0.705790            0.790052           0.710384   \n",
       "9            0.703634            0.771500           0.707879   \n",
       "10           0.705788            0.789147           0.710111   \n",
       "11           0.702917            0.769467           0.707125   \n",
       "12           0.705815            0.789783           0.710312   \n",
       "13           0.703633            0.771500           0.707880   \n",
       "14           0.705755            0.788905           0.710066   \n",
       "15           0.702917            0.769466           0.707124   \n",
       "16           0.658843            0.993073           0.667767   \n",
       "17           0.705059            0.889704           0.708131   \n",
       "18           0.658194            0.993066           0.667246   \n",
       "19           0.703907            0.890988           0.705403   \n",
       "20           0.658757            0.993252           0.667393   \n",
       "21           0.705010            0.889704           0.708139   \n",
       "22           0.658007            0.993245           0.666673   \n",
       "23           0.703897            0.890988           0.705413   \n",
       "24           0.693641            0.827309           0.690840   \n",
       "25           0.686589            0.812174           0.684539   \n",
       "26           0.693591            0.827018           0.690594   \n",
       "27           0.685207            0.803468           0.683229   \n",
       "28           0.693865            0.827775           0.690553   \n",
       "29           0.686589            0.812174           0.684539   \n",
       "30           0.693360            0.826075           0.689775   \n",
       "31           0.685207            0.803468           0.683229   \n",
       "32           0.717455            0.901646           0.719335   \n",
       "33           0.713310            0.864153           0.715611   \n",
       "34           0.717483            0.901070           0.719360   \n",
       "35           0.712276            0.860441           0.714394   \n",
       "36           0.717146            0.903512           0.719831   \n",
       "37           0.713310            0.864153           0.715611   \n",
       "38           0.717458            0.899637           0.719269   \n",
       "39           0.712276            0.860441           0.714394   \n",
       "40           0.654888            0.996046           0.668716   \n",
       "41           0.709562            0.966442           0.710852   \n",
       "42           0.670010            0.992782           0.676019   \n",
       "43           0.707317            0.967103           0.708329   \n",
       "44           0.661323            0.995104           0.668669   \n",
       "45           0.709562            0.966442           0.710852   \n",
       "46           0.676567            0.990989           0.691876   \n",
       "47           0.707317            0.967103           0.708329   \n",
       "\n",
       "    split3_train_score  split4_test_score  split4_train_score  std_fit_time  \\\n",
       "0             0.739512           0.686958            0.739901      6.296197   \n",
       "1             0.735341           0.683635            0.735345     10.800199   \n",
       "2             0.739291           0.686518            0.739841      6.760962   \n",
       "3             0.734912           0.683079            0.735058     10.234684   \n",
       "4             0.739445           0.686919            0.739804      9.765571   \n",
       "5             0.735341           0.683634            0.735345     10.544492   \n",
       "6             0.739225           0.686497            0.739757      9.689095   \n",
       "7             0.734912           0.683081            0.735058      8.128833   \n",
       "8             0.788982           0.702574            0.791762     13.599501   \n",
       "9             0.770177           0.701354            0.773197     18.432759   \n",
       "10            0.788221           0.702291            0.790872     19.351206   \n",
       "11            0.768158           0.700843            0.771168     18.036368   \n",
       "12            0.788687           0.702553            0.791518     21.270948   \n",
       "13            0.770177           0.701354            0.773196     16.367125   \n",
       "14            0.787961           0.702299            0.790653     16.114625   \n",
       "15            0.768158           0.700844            0.771168     16.542563   \n",
       "16            0.993054           0.667996            0.993161     37.440139   \n",
       "17            0.888875           0.698898            0.889706     36.048994   \n",
       "18            0.993082           0.667369            0.993197     32.022203   \n",
       "19            0.890251           0.696301            0.890958     30.695872   \n",
       "20            0.993230           0.667564            0.993351     34.962922   \n",
       "21            0.888875           0.698915            0.889706     34.571807   \n",
       "22            0.993273           0.667271            0.993369     26.748914   \n",
       "23            0.890251           0.696298            0.890958     25.248289   \n",
       "24            0.829522           0.687299            0.811986      0.404963   \n",
       "25            0.790225           0.680965            0.805462      0.406666   \n",
       "26            0.828276           0.687665            0.822732      0.409550   \n",
       "27            0.781214           0.681356            0.812356      0.718872   \n",
       "28            0.825776           0.688442            0.826927      0.372363   \n",
       "29            0.790225           0.680965            0.805462      0.111057   \n",
       "30            0.826707           0.686629            0.812272      0.136459   \n",
       "31            0.781214           0.681356            0.812356      0.440704   \n",
       "32            0.894059           0.713699            0.903550      0.569852   \n",
       "33            0.864961           0.709577            0.865795      0.425130   \n",
       "34            0.902018           0.713066            0.901396      0.350147   \n",
       "35            0.861697           0.708125            0.862363      0.136298   \n",
       "36            0.904748           0.713206            0.902602      0.548195   \n",
       "37            0.864961           0.709577            0.865795      0.137832   \n",
       "38            0.892224           0.713473            0.883174      0.466359   \n",
       "39            0.861697           0.708125            0.862363      0.154530   \n",
       "40            0.994942           0.670470            0.994292      1.387123   \n",
       "41            0.963240           0.705382            0.966758      1.768423   \n",
       "42            0.992690           0.691380            0.984004      0.965489   \n",
       "43            0.967246           0.703272            0.966760      1.277149   \n",
       "44            0.995027           0.674349            0.993350      2.309415   \n",
       "45            0.963240           0.705382            0.966758      2.540169   \n",
       "46            0.985131           0.678515            0.991730      1.872970   \n",
       "47            0.967246           0.703272            0.966760      1.965618   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "0         0.034365        0.006034         0.001505  \n",
       "1         0.114739        0.005687         0.001542  \n",
       "2         0.047188        0.006008         0.001486  \n",
       "3         0.041004        0.005683         0.001535  \n",
       "4         0.081701        0.006036         0.001506  \n",
       "5         0.097727        0.005694         0.001542  \n",
       "6         0.053234        0.005999         0.001486  \n",
       "7         0.039917        0.005679         0.001535  \n",
       "8         0.060125        0.007254         0.001497  \n",
       "9         0.069059        0.006638         0.001676  \n",
       "10        0.043090        0.007221         0.001498  \n",
       "11        0.049416        0.006720         0.001583  \n",
       "12        0.039877        0.007237         0.001507  \n",
       "13        0.043901        0.006627         0.001676  \n",
       "14        0.037720        0.007213         0.001503  \n",
       "15        0.046796        0.006738         0.001583  \n",
       "16        0.046954        0.005400         0.000058  \n",
       "17        0.028334        0.007401         0.000952  \n",
       "18        0.005106        0.005022         0.000064  \n",
       "19        0.081746        0.007165         0.000958  \n",
       "20        0.047893        0.005202         0.000057  \n",
       "21        0.107082        0.007386         0.000952  \n",
       "22        0.039035        0.004997         0.000055  \n",
       "23        0.068906        0.007164         0.000958  \n",
       "24        0.055687        0.005429         0.006217  \n",
       "25        0.011379        0.004983         0.008376  \n",
       "26        0.026512        0.005469         0.003167  \n",
       "27        0.075165        0.004337         0.012358  \n",
       "28        0.046577        0.006094         0.008870  \n",
       "29        0.057741        0.004983         0.008376  \n",
       "30        0.078249        0.005320         0.005698  \n",
       "31        0.008356        0.004337         0.012358  \n",
       "32        0.027323        0.006299         0.003497  \n",
       "33        0.023332        0.006201         0.000519  \n",
       "34        0.054763        0.006555         0.003483  \n",
       "35        0.018397        0.006268         0.000687  \n",
       "36        0.034357        0.006274         0.000712  \n",
       "37        0.066871        0.006201         0.000519  \n",
       "38        0.067053        0.006612         0.006848  \n",
       "39        0.050099        0.006268         0.000687  \n",
       "40        0.060299        0.010297         0.000937  \n",
       "41        0.047552        0.006551         0.001241  \n",
       "42        0.064409        0.007225         0.003891  \n",
       "43        0.110016        0.005222         0.013749  \n",
       "44        0.391801        0.009021         0.001215  \n",
       "45        0.465775        0.006551         0.001241  \n",
       "46        0.153124        0.005271         0.004293  \n",
       "47        0.097668        0.005222         0.013749  \n",
       "\n",
       "[48 rows x 25 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display grid search results\n",
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons à présent un modèle avec plusieurs paramètres bien définis permettant d'obtenir une bonne accuracy. \n",
    "Nous discuterons dans la conclusions des lessons à garder de cette recherche et des améliorations à lui apporter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Conclusion\n",
    "\n",
    "Malgré un problème qui peut sembler simple, il est vrai que la difficulté est au rendez-vous pour augmenter les performances actuelles. \n",
    "\n",
    "Premièrement, après une première analyse des données, notre modèle mathématique doit arriver à intégrer une notion générale de l'utilité. Après une exploration des données, les reviews intutiles peuvent s'apparenter à des experiences personnelles ou des histoire qui n'ont pas forcément un rapport direct avec le produit. Alors que les review utiles sont plus informatives sur le produit en lui-même.\n",
    "\n",
    "Deuxièmement, la plupart des algorithmes de classification utilisés ont commun point commun d'être linéaire, assumant donc que nos données sont linéairement séparable. Cependant, plusieurs publications scientifiques et quelques testes effectué ici ont démontré que des classificateurs non-linéaires n'étaient pas forcément plus performant en terme de précision.\n",
    "\n",
    "Au final, nous avons obtenues des performances correctes, en tout cas meilleures que des estimateurs aléatoires. Nous avons réussi à construire un modèle mathématiques plus ou moins performant. Voici les différents enseignements et améliorations possibles pour de futurs expériences :\n",
    "\n",
    "- L'ensemble des données sont à analyser avec minutie et peuvent apporter de légères améliorations, mais surtout une bonne compréhension sur leurs diverses propriétés. Cependant, trop de features inutiles  pourrait ajouter du bruit (noise) et réduire notre précision.\n",
    "\n",
    "- L'analyse des possible pre-process en NLP a été très instructive. En effet, LSA est souvent plus performant dans le cas de classification de textes en diverses catégories, mais c'est montré peu utile pour notre problème.\n",
    "\n",
    "- Nous avons fait une analyse des différents classificateurs, mais cela aurait pu être plus rigoureux avec une cross-validation et une utilisation de grid search pour tester l'ensemble des paramètres. Mais les premiers essais nous ont permis d'avoir une premières approche sur le problème.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futurs modèles à tester\n",
    "\n",
    "- word2vec : un neural network à deux layer permettant de capturer des features sémantiques plus abstraites et pouvant être utilisé à la place ou en combinaison de TFIDF, comme présenté sur [DS-Lore](http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/). word2vec a démontré de bonne modélisation de textes et de bonne performances en ce qui concerne la précision.\n",
    "- CNN for NLP : Des [exemples](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/) d'implémentations de CNN pour la classification de textes montre de bonne performances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classification avec le test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Dataset\n",
    "X_train, y_train = train_full[\n",
    "    ['ID', \n",
    "     'review_title', \n",
    "     'review_content', \n",
    "     'review_stars', \n",
    "     'product']\n",
    "], train_full['Target']\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Classification pipeline\n",
    "clf = Pipeline([\n",
    "    ('union', FeatureUnion([\n",
    "        ('title', Pipeline([\n",
    "            ('select', ItemSelector(key=\"review_title\")),\n",
    "            ('tfidf', TfidfVectorizer())\n",
    "        ])),\n",
    "        ('content', Pipeline([\n",
    "            ('select', ItemSelector(key=\"review_content\")),\n",
    "            (\n",
    "                'tfidf', \n",
    "                TfidfVectorizer(\n",
    "                    smooth_idf=True, \n",
    "                    sublinear_tf=True, \n",
    "                    norm='l2'\n",
    "                )\n",
    "            )\n",
    "        ])),\n",
    "         ('context_stats', Pipeline([\n",
    "                ('select', ItemSelector(key='review_content')),\n",
    "                ('stats', TextStats()),  \n",
    "                ('vect', DictVectorizer()), \n",
    "            ])),\n",
    "    ])),\n",
    "    ('clf', LogisticRegression(penalty='l2'))\n",
    "])\n",
    "\n",
    "# train model \n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# test prediction\n",
    "y_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce submission file\n",
    "submission = pd.DataFrame({\n",
    "    'ID' : X_test['ID'],\n",
    "    'Target' : y_test\n",
    "})\n",
    "submission.to_csv(\n",
    "    path_or_buf='christopher_salotti_submission.csv', \n",
    "    index=False, \n",
    "    sep=';'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export Notebook in HTML\n",
    "import os \n",
    "\n",
    "os.system('jupyter nbconvert --to html linkvalue_challenge.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
